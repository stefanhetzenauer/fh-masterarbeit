{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = ''\n",
    "DATASET_NAME = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, split=0.3):\n",
    "  y = df['label']\n",
    "  X = df.drop(columns=['label'])\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [3200, 5000]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [100, 500, 1000]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [100, 500, 1000]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [2, 4, 10, 25, 50]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]# Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    return random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "  df = pd.read_csv(path, sep=';', encoding='utf-8')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, name, binary=False):\n",
    "    if binary:\n",
    "        df = create_balanced_dataset(load_data(path))\n",
    "    else:\n",
    "        df = load_data(path)\n",
    "    \n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    random_grid = create_grid()\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    rf_random = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=random_grid,\n",
    "        n_iter=25,\n",
    "        cv=3,\n",
    "        verbose=2,\n",
    "        random_state=161194,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    print('Score: ', rf_random.best_score_)\n",
    "    print('Estimator: ', rf_random.best_estimator_)\n",
    "    \n",
    "    y_pred = rf_random.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    cm = pd.DataFrame(confusion_matrix(y_test, y_pred))\n",
    "    cm_norm = pd.DataFrame(confusion_matrix(y_test, y_pred, normalize='true'))\n",
    "    \n",
    "    print(cm)\n",
    "    print(cm_norm)\n",
    "    \n",
    "    cm.to_csv(BASE_PATH + r'results/' + name + 'cm.csv', sep=';', encoding='utf-8', index=False)\n",
    "    cm_norm.to_csv(BASE_PATH + r'results/' + name + 'norm_cm.csv', sep=';', encoding='utf-8', index=False)\n",
    "    \n",
    "    with open(BASE_PATH + r'results/' + f'{name}model.pkl', 'wb') as file:\n",
    "        pickle.dump(rf_random, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    df_0 = df[df['label'] == 0]\n",
    "    df_1 = df[df['label'] == 1].sample(n=2500)\n",
    "    df_2 = df[df['label'] == 2].sample(n=2500)\n",
    "    \n",
    "    return pd.concat([df_0, df_1, df_2]).replace(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'128_QF95-{DATASET_NAME}.csv', f'RF_128_QF-95_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'128_QF98-{DATASET_NAME}.csv', f'RF_128_QF-98_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'128_QF100-{DATASET_NAME}.csv', f'RF_128_QF-100_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'64_QF95-{DATASET_NAME}.csv', f'RF_64_QF-95_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'64_QF98-{DATASET_NAME}.csv', f'RF_64_QF-98_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'64_QF100-{DATASET_NAME}.csv', f'RF_64_QF-100_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'64_asc-{DATASET_NAME}.csv', f'RF_64_ASC_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'64_desc-{DATASET_NAME}.csv', f'RF_64_DESC_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'128_asc-{DATASET_NAME}.csv', f'RF_128_ASC_{DATASET_NAME}_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-tuning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(BASE_PATH + f'128_desc-{DATASET_NAME}.csv', f'RF_128_DESC_{DATASET_NAME}_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}